---
title: "EDA"
author: "Chhiring Lama"
date: "2024-10-03"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(haven)
```

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728", "USW00022534", "USS0023B17S"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2021-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(
      id, 
      USW00094728 = "CentralPark_NY", 
      USW00022534 = "Molokai_HI",
      USS0023B17S = "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10,
    month = lubridate::floor_date(date, unit = "month")) |>
  select(name, id, everything())

weather_df
```

Lets make some plot
```{r}
weather_df |> 
  ggplot(aes(x = prcp)) +
  geom_histogram()
```

```{r}
weather_df |>
  filter(prcp > 1000)
```

```{r}
weather_df |> 
  filter(tmax > 20, tmax < 30) |> 
  ggplot(aes(x = tmin, y = tmax, color = name, shape = name)) +
  geom_point()
```

Central park and Molakai's tmax is different (more separated) than Waterhole. 

## group_by()

```{r}
weather_df |> 
  group_by(name)
```

counting the values
```{r}
weather_df |> 
  group_by(name) |> 
  summarize(n_obs = n(), 
            n_dist = n_distinct(month))
```

## 2x2 tables

```{r}
weather_df |> 
  drop_na(tmax) |> 
  mutate(
    cold_cat = case_when(
      tmax < 5 ~ "cold", 
      tmax >= 5 ~ "not cold"
    )
  ) |> 
  group_by(name, cold_cat) |> 
  summarize(count = n()) |> 
  pivot_wider(
    names_from = "cold_cat",
    values_from = "count"
  )
```

```{r}
weather_df |> 
  drop_na(tmax) |> 
  mutate(
    cold_cat = case_when(
      tmax < 5 ~ "cold", 
      tmax >= 5 ~ "not cold"
    )
  ) |> 
  janitor::tabyl(name, cold_cat)
```

## General Numeric Summaries

Computing other useful summaries:
```{r}
weather_df |> 
  group_by(name) |> 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE), 
    median_tmin = median(tmin, a.rm = TRUE), 
    sd_prcp = sd(prcp, na.rm = TRUE)
  )
```

plot one of the summaries: 
```{r}
weather_df |> 
  group_by(name, month) |> 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE), 
    median_tmin = median(tmin, a.rm = TRUE), 
    sd_prcp = sd(prcp, na.rm = TRUE)
  ) |> 
  ggplot(aes(x = month, y = mean_tmax, color = name)) +
  geom_point() +
  geom_line()
```

Format for readers
```{r}
weather_df |> 
  group_by(name, month) |> 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE)
  ) |> 
  pivot_wider(
    names_from = name,
    values_from = mean_tmax
  ) |> 
  knitr::kable(digits = 3, 
                col.names = c("Month", "Central Park", "Molokai", "Waterhole"))
```

## grouped mutate
```{r}
weather_df |> 
  group_by(name) |> 
  mutate(mean_tmax = mean(tmax, na.rm = TRUE), 
         centered_tmax = tmax - mean_tmax) |> 
  ggplot(aes(x = date, y = centered_tmax, color = name)) +
  geom_point()
```

## window functions

Find hottest/ coldest days
```{r}
weather_df |> 
  group_by(name) |> 
  mutate(
    temp_rank = min_rank(tmax)
  ) |> 
  filter(temp_rank < 4)

weather_df |> 
  group_by(name) |> 
  filter(min_rank(tmax) < 4) |> 
  arrange(tmax)
```

Lagged information (creating a color and shifting down by one row, data needs to be pre-ordered)
```{r}
weather_df |> 
  group_by(name) |> 
  mutate(
    lagged_temp = lag(tmax), 
    temp_change = tmax - lagged_temp
  ) |> 
  filter(min_rank(temp_change) < 3) |> 
  arrange(desc(abs(temp_change)))
```

```{r}
weather_df |> 
  group_by(name) |> 
  mutate(
    lagged_temp = lag(tmax), 
    temp_change = tmax - lagged_temp
  ) |> 
  summarize(
    sd_tmax_change = sd(temp_change, na.rm = TRUE)
  )
```

## Learning Assessment1: 
In the PULSE data, the primary outcome is BDI score; itâ€™s observed over follow-up visits, and we might ask if the typical BDI score values are roughly similar at each. Try to write a code chunk that imports, cleans, and summarizes the PULSE data to examine the mean and median at each visit. Export the results of this in a reader-friendly format.

### Solution:

```{r}
pulse_df <- read_sas("Data/public_pulse_data.sas7bdat") |> 
  janitor::clean_names() |> 
  pivot_longer(
    bdi_score_bl:bdi_score_12m, 
    names_to = "visit", 
    values_to = "bdi_score", 
    names_prefix = "bdi_score_"
  )

pulse_df |> 
  group_by(visit) |> 
  summarize(
    mean_bdi = mean(bdi_score, na.rm = TRUE), 
    median_bdi = median(bdi_score, na.rm = TRUE)
  ) |> 
    knitr::kable(digits = 1)
```

## Learning Assessment2: 
In the FAS data, there are several outcomes of interest; for now, focus on post-natal day on which a pup is able to pivot. Two predictors of interest are the dose level and the day of treatment. Produce a reader-friendly table that quantifies the possible associations between dose, day of treatment, and the ability to pivot.

### Solution:
```{r}
litters_df <- read_csv("./data/FAS_litters.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |> 
  separate(group, into = c("dose", "day_of_tx"), sep = 3)

pups_df <- read_csv("./data/FAS_pups.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  mutate(
    sex = 
      case_match(
        sex, 
        1 ~ "male", 
        2 ~ "female"))

fas_df = left_join(pups_df, litters_df, by = "litter_number") 
```

Compute the table needed:
```{r}
fas_df |> 
  drop_na(dose) |> 
  group_by(dose, day_of_tx) |> 
  summarize(
    mean_pivot = mean(pd_pivot, na.rm = TRUE)
  ) |> 
  pivot_wider(
    names_from = day_of_tx, 
    values_from = mean_pivot, 
  ) |> 
  knitr::kable(digits = 2)
```




